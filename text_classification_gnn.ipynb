{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oIlllyQ61WS_",
        "flz6zwAmfjJn",
        "uQRRTLCJf9hj",
        "oR8eh-ywz8eL",
        "cB_Q0pu9dco-",
        "coVvBe9p4JfG",
        "gnhkyFEE4JfR",
        "5mhyf5Lw4Pwh",
        "HRYq5R9P4Pwi",
        "55UF7Kt04Pwj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification"
      ],
      "metadata": {
        "id": "_evIlRcSdEXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "4twTF-Cieopv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spektral > /dev/null\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from spektral.data.loaders import SingleLoader\n",
        "from spektral.datasets.citation import Citation\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from spektral.layers import GCNConv\n",
        "from spektral.models.gcn import GCN\n",
        "from spektral.transforms import LayerPreprocess\n"
      ],
      "metadata": {
        "id": "CSLOIMYMd-_J"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "HgdWpulRfMbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN Model"
      ],
      "metadata": {
        "id": "1UWL1w7MfbVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_weights(mask):\n",
        "    return mask.astype(np.float32) / np.count_nonzero(mask)\n",
        "\n",
        "\n",
        "def create_GCN_text_classification(dataset, learning_rate):\n",
        "  weights_tr, weights_va, weights_te = (\n",
        "      mask_to_weights(mask)\n",
        "      for mask in (dataset.mask_tr, dataset.mask_va, dataset.mask_te)\n",
        "  )\n",
        "\n",
        "  model = GCN(n_labels=dataset.n_labels)\n",
        "  model.compile(\n",
        "      optimizer=Adam(learning_rate),\n",
        "      loss=CategoricalCrossentropy(reduction=\"sum\"),\n",
        "      weighted_metrics=[\"acc\"],\n",
        "  )\n",
        "  return model, weights_tr, weights_va, weights_te"
      ],
      "metadata": {
        "id": "X_IvBxLwfZqb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simplify GCN Model"
      ],
      "metadata": {
        "id": "5Erq1aK39lUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGCN:\n",
        "    def __init__(self, K):\n",
        "        self.K = K\n",
        "\n",
        "    def __call__(self, graph):\n",
        "        out = graph.a\n",
        "        for _ in range(self.K - 1):\n",
        "            out = out.dot(out)\n",
        "        out.sort_indices()\n",
        "        graph.a = out\n",
        "        return graph"
      ],
      "metadata": {
        "id": "rb0gNnoK9tGV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_SGCN_text_classification(database, learning_rate):\n",
        "  l2_reg = 5e-6\n",
        "  a_dtype = dataset[0].a.dtype\n",
        "  N = dataset.n_nodes  # Number of nodes in the graph\n",
        "  F = dataset.n_node_features  # Original size of node features\n",
        "  n_out = dataset.n_labels  # Number of classes\n",
        "\n",
        "  # Model definition\n",
        "  x_in = Input(shape=(F,))\n",
        "  a_in = Input((N,), sparse=True, dtype=a_dtype)\n",
        "\n",
        "  output = GCNConv(\n",
        "      n_out, activation=\"softmax\", kernel_regularizer=l2(l2_reg), use_bias=False\n",
        "  )([x_in, a_in])\n",
        "\n",
        "  # Build model\n",
        "  model = Model(inputs=[x_in, a_in], outputs=output)\n",
        "  optimizer = Adam(learning_rate=learning_rate)\n",
        "  model.compile(\n",
        "      optimizer=optimizer, loss=\"categorical_crossentropy\", weighted_metrics=[\"acc\"]\n",
        "  )\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "7-Gxwp1xvdWz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cora"
      ],
      "metadata": {
        "id": "Msg8SkjXdJdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "seed = 0\n",
        "epochs = 200\n",
        "patience = 10\n",
        "data = \"cora\"\n",
        "tf.random.set_seed(seed=seed)"
      ],
      "metadata": {
        "id": "3-7yHcCQdn9v"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN Model"
      ],
      "metadata": {
        "id": "oIlllyQ61WS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Citation(data, normalize_x=True, transforms=[LayerPreprocess(GCNConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jnYW5zqdzKA",
        "outputId": "562fdae9-a02d-4494-b56f-d35f9b19545c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model"
      ],
      "metadata": {
        "id": "flz6zwAmfjJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, weights_tr, weights_va, weights_te = create_GCN_text_classification(dataset, learning_rate)\n",
        "loader_tr = SingleLoader(dataset, sample_weights=weights_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUsAF0oUfgOY",
        "outputId": "8c8865c3-a2fd-4c5f-9e53-34b66c7e7b85"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9543 - acc: 0.1214 - val_loss: 1.9510 - val_acc: 0.2440\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 1.9485 - acc: 0.2786 - val_loss: 1.9477 - val_acc: 0.4140\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 1.9424 - acc: 0.5643 - val_loss: 1.9443 - val_acc: 0.4880\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 1.9368 - acc: 0.5929 - val_loss: 1.9407 - val_acc: 0.5080\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 1.9276 - acc: 0.6643 - val_loss: 1.9373 - val_acc: 0.4680\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.9222 - acc: 0.5786 - val_loss: 1.9340 - val_acc: 0.4600\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 1.9150 - acc: 0.6000 - val_loss: 1.9309 - val_acc: 0.4440\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 1.9078 - acc: 0.5571 - val_loss: 1.9277 - val_acc: 0.4360\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.8993 - acc: 0.5714 - val_loss: 1.9245 - val_acc: 0.4360\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.8916 - acc: 0.5786 - val_loss: 1.9212 - val_acc: 0.4360\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.8832 - acc: 0.5429 - val_loss: 1.9179 - val_acc: 0.4380\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 1.8750 - acc: 0.5929 - val_loss: 1.9146 - val_acc: 0.4460\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 1.8631 - acc: 0.6214 - val_loss: 1.9113 - val_acc: 0.4460\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.8609 - acc: 0.6143 - val_loss: 1.9079 - val_acc: 0.4520\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 1.8411 - acc: 0.6643 - val_loss: 1.9045 - val_acc: 0.4540\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 1.8383 - acc: 0.6571 - val_loss: 1.9009 - val_acc: 0.4600\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 1.8254 - acc: 0.6571 - val_loss: 1.8973 - val_acc: 0.4580\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 270ms/step - loss: 1.8174 - acc: 0.6929 - val_loss: 1.8937 - val_acc: 0.4640\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.8068 - acc: 0.6643 - val_loss: 1.8898 - val_acc: 0.4640\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.7939 - acc: 0.6929 - val_loss: 1.8859 - val_acc: 0.4680\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 1.7794 - acc: 0.6929 - val_loss: 1.8820 - val_acc: 0.4740\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 1.7739 - acc: 0.7000 - val_loss: 1.8780 - val_acc: 0.4780\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 1.7668 - acc: 0.6857 - val_loss: 1.8739 - val_acc: 0.4800\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 1.7540 - acc: 0.7000 - val_loss: 1.8696 - val_acc: 0.4860\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.7467 - acc: 0.6714 - val_loss: 1.8651 - val_acc: 0.4920\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 1.7181 - acc: 0.6786 - val_loss: 1.8606 - val_acc: 0.4960\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.7220 - acc: 0.6571 - val_loss: 1.8562 - val_acc: 0.5000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 1.7153 - acc: 0.6929 - val_loss: 1.8517 - val_acc: 0.5040\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.6924 - acc: 0.7214 - val_loss: 1.8471 - val_acc: 0.5120\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 1.6743 - acc: 0.6786 - val_loss: 1.8423 - val_acc: 0.5120\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.6710 - acc: 0.7000 - val_loss: 1.8375 - val_acc: 0.5140\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.6693 - acc: 0.7214 - val_loss: 1.8325 - val_acc: 0.5180\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 1.6485 - acc: 0.7071 - val_loss: 1.8272 - val_acc: 0.5180\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 1.5996 - acc: 0.7786 - val_loss: 1.8217 - val_acc: 0.5200\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 1.6071 - acc: 0.6786 - val_loss: 1.8161 - val_acc: 0.5220\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 1.6017 - acc: 0.7500 - val_loss: 1.8105 - val_acc: 0.5280\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 1.6053 - acc: 0.7143 - val_loss: 1.8047 - val_acc: 0.5280\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 1.5655 - acc: 0.7571 - val_loss: 1.7990 - val_acc: 0.5340\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 1.5553 - acc: 0.7643 - val_loss: 1.7933 - val_acc: 0.5400\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.5307 - acc: 0.7643 - val_loss: 1.7875 - val_acc: 0.5440\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 1.5367 - acc: 0.7714 - val_loss: 1.7820 - val_acc: 0.5460\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.5086 - acc: 0.7500 - val_loss: 1.7764 - val_acc: 0.5500\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 1.4888 - acc: 0.7714 - val_loss: 1.7706 - val_acc: 0.5500\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 1.4990 - acc: 0.7786 - val_loss: 1.7645 - val_acc: 0.5500\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 1.4773 - acc: 0.8000 - val_loss: 1.7582 - val_acc: 0.5500\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 1.4793 - acc: 0.7643 - val_loss: 1.7518 - val_acc: 0.5540\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 1.4330 - acc: 0.7714 - val_loss: 1.7454 - val_acc: 0.5580\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 1.4570 - acc: 0.8071 - val_loss: 1.7388 - val_acc: 0.5620\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.4422 - acc: 0.7786 - val_loss: 1.7321 - val_acc: 0.5640\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.4113 - acc: 0.8071 - val_loss: 1.7253 - val_acc: 0.5700\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 1.4033 - acc: 0.8000 - val_loss: 1.7185 - val_acc: 0.5700\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 1.3609 - acc: 0.8000 - val_loss: 1.7115 - val_acc: 0.5720\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.3998 - acc: 0.7929 - val_loss: 1.7044 - val_acc: 0.5720\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.3484 - acc: 0.8000 - val_loss: 1.6970 - val_acc: 0.5760\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.3036 - acc: 0.8357 - val_loss: 1.6894 - val_acc: 0.5760\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 1.3235 - acc: 0.8357 - val_loss: 1.6818 - val_acc: 0.5780\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 1.3054 - acc: 0.8286 - val_loss: 1.6742 - val_acc: 0.5840\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 1.3102 - acc: 0.8357 - val_loss: 1.6666 - val_acc: 0.5880\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 1.3126 - acc: 0.8286 - val_loss: 1.6590 - val_acc: 0.5940\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 1.3016 - acc: 0.8214 - val_loss: 1.6511 - val_acc: 0.5980\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.2679 - acc: 0.8286 - val_loss: 1.6432 - val_acc: 0.6040\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 1.2451 - acc: 0.8786 - val_loss: 1.6351 - val_acc: 0.6080\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 1.2395 - acc: 0.8500 - val_loss: 1.6269 - val_acc: 0.6180\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.2207 - acc: 0.8500 - val_loss: 1.6188 - val_acc: 0.6280\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 1.2245 - acc: 0.8786 - val_loss: 1.6105 - val_acc: 0.6340\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 1.2151 - acc: 0.8357 - val_loss: 1.6023 - val_acc: 0.6460\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 1.1808 - acc: 0.8857 - val_loss: 1.5940 - val_acc: 0.6520\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.2027 - acc: 0.8857 - val_loss: 1.5858 - val_acc: 0.6560\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 1.2036 - acc: 0.8571 - val_loss: 1.5773 - val_acc: 0.6680\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 1.1422 - acc: 0.8571 - val_loss: 1.5693 - val_acc: 0.6800\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 1.1134 - acc: 0.9071 - val_loss: 1.5612 - val_acc: 0.6820\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.1561 - acc: 0.8500 - val_loss: 1.5531 - val_acc: 0.6880\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 1.1523 - acc: 0.8857 - val_loss: 1.5450 - val_acc: 0.6900\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 1.1345 - acc: 0.8643 - val_loss: 1.5368 - val_acc: 0.7000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 1.1047 - acc: 0.9000 - val_loss: 1.5285 - val_acc: 0.7060\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 1.1258 - acc: 0.8786 - val_loss: 1.5205 - val_acc: 0.7100\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.0822 - acc: 0.9000 - val_loss: 1.5125 - val_acc: 0.7160\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.0923 - acc: 0.8929 - val_loss: 1.5045 - val_acc: 0.7200\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.0461 - acc: 0.9429 - val_loss: 1.4967 - val_acc: 0.7280\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 1.0457 - acc: 0.9143 - val_loss: 1.4888 - val_acc: 0.7300\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.0911 - acc: 0.8786 - val_loss: 1.4808 - val_acc: 0.7300\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 1.0381 - acc: 0.9429 - val_loss: 1.4731 - val_acc: 0.7340\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.0711 - acc: 0.9000 - val_loss: 1.4655 - val_acc: 0.7360\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 1.0320 - acc: 0.9357 - val_loss: 1.4581 - val_acc: 0.7380\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 1.0113 - acc: 0.9214 - val_loss: 1.4504 - val_acc: 0.7400\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.0117 - acc: 0.9214 - val_loss: 1.4430 - val_acc: 0.7420\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 1.0168 - acc: 0.9071 - val_loss: 1.4354 - val_acc: 0.7480\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0046 - acc: 0.9429 - val_loss: 1.4280 - val_acc: 0.7540\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 1.0013 - acc: 0.9071 - val_loss: 1.4208 - val_acc: 0.7560\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 1.0022 - acc: 0.9214 - val_loss: 1.4135 - val_acc: 0.7620\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.9416 - acc: 0.9429 - val_loss: 1.4065 - val_acc: 0.7620\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 1.0085 - acc: 0.8857 - val_loss: 1.3996 - val_acc: 0.7620\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.9525 - acc: 0.9500 - val_loss: 1.3932 - val_acc: 0.7620\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9978 - acc: 0.9214 - val_loss: 1.3873 - val_acc: 0.7640\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.9902 - acc: 0.9286 - val_loss: 1.3814 - val_acc: 0.7660\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.9371 - acc: 0.9000 - val_loss: 1.3758 - val_acc: 0.7660\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.9276 - acc: 0.9571 - val_loss: 1.3708 - val_acc: 0.7660\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.9334 - acc: 0.9000 - val_loss: 1.3661 - val_acc: 0.7680\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.9241 - acc: 0.9500 - val_loss: 1.3618 - val_acc: 0.7700\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.9164 - acc: 0.9571 - val_loss: 1.3578 - val_acc: 0.7720\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.8930 - acc: 0.9429 - val_loss: 1.3535 - val_acc: 0.7740\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8978 - acc: 0.9500 - val_loss: 1.3494 - val_acc: 0.7740\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 0.9268 - acc: 0.9500 - val_loss: 1.3454 - val_acc: 0.7740\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.9527 - acc: 0.9429 - val_loss: 1.3414 - val_acc: 0.7740\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.8773 - acc: 0.9357 - val_loss: 1.3374 - val_acc: 0.7740\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.8928 - acc: 0.9357 - val_loss: 1.3333 - val_acc: 0.7740\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.9025 - acc: 0.9429 - val_loss: 1.3290 - val_acc: 0.7740\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.8270 - acc: 0.9357 - val_loss: 1.3250 - val_acc: 0.7740\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.9120 - acc: 0.9571 - val_loss: 1.3214 - val_acc: 0.7700\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.8956 - acc: 0.9357 - val_loss: 1.3174 - val_acc: 0.7700\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8576 - acc: 0.9571 - val_loss: 1.3132 - val_acc: 0.7700\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.8755 - acc: 0.9643 - val_loss: 1.3092 - val_acc: 0.7680\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.8267 - acc: 0.9786 - val_loss: 1.3042 - val_acc: 0.7720\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.8628 - acc: 0.9429 - val_loss: 1.2989 - val_acc: 0.7720\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.8374 - acc: 0.9286 - val_loss: 1.2938 - val_acc: 0.7740\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.8898 - acc: 0.9429 - val_loss: 1.2889 - val_acc: 0.7740\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.8190 - acc: 0.9429 - val_loss: 1.2841 - val_acc: 0.7740\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.8250 - acc: 0.9643 - val_loss: 1.2795 - val_acc: 0.7740\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8391 - acc: 0.9643 - val_loss: 1.2748 - val_acc: 0.7740\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.8258 - acc: 0.9714 - val_loss: 1.2701 - val_acc: 0.7720\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.8150 - acc: 0.9643 - val_loss: 1.2655 - val_acc: 0.7720\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.8203 - acc: 0.9357 - val_loss: 1.2608 - val_acc: 0.7740\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.8229 - acc: 0.9429 - val_loss: 1.2566 - val_acc: 0.7760\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.8226 - acc: 0.9429 - val_loss: 1.2523 - val_acc: 0.7760\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.8446 - acc: 0.9643 - val_loss: 1.2482 - val_acc: 0.7760\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.8422 - acc: 0.9571 - val_loss: 1.2448 - val_acc: 0.7800\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.8164 - acc: 0.9643 - val_loss: 1.2422 - val_acc: 0.7800\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.8457 - acc: 0.9500 - val_loss: 1.2392 - val_acc: 0.7800\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.7900 - acc: 0.9643 - val_loss: 1.2363 - val_acc: 0.7800\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.8299 - acc: 0.9500 - val_loss: 1.2342 - val_acc: 0.7800\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.8033 - acc: 0.9500 - val_loss: 1.2323 - val_acc: 0.7780\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.7515 - acc: 0.9643 - val_loss: 1.2304 - val_acc: 0.7780\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.7712 - acc: 0.9714 - val_loss: 1.2290 - val_acc: 0.7800\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.7863 - acc: 0.9571 - val_loss: 1.2273 - val_acc: 0.7780\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.7584 - acc: 0.9643 - val_loss: 1.2257 - val_acc: 0.7780\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.7759 - acc: 0.9571 - val_loss: 1.2236 - val_acc: 0.7780\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.7299 - acc: 0.9571 - val_loss: 1.2211 - val_acc: 0.7780\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.8136 - acc: 0.9571 - val_loss: 1.2191 - val_acc: 0.7780\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.8012 - acc: 0.9500 - val_loss: 1.2164 - val_acc: 0.7780\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.7865 - acc: 0.9571 - val_loss: 1.2132 - val_acc: 0.7760\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.7716 - acc: 0.9429 - val_loss: 1.2100 - val_acc: 0.7740\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.7484 - acc: 0.9643 - val_loss: 1.2068 - val_acc: 0.7760\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.7180 - acc: 0.9714 - val_loss: 1.2034 - val_acc: 0.7760\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.7242 - acc: 0.9786 - val_loss: 1.2002 - val_acc: 0.7760\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7688 - acc: 0.9143 - val_loss: 1.1973 - val_acc: 0.7760\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.7461 - acc: 0.9429 - val_loss: 1.1948 - val_acc: 0.7760\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.7378 - acc: 0.9286 - val_loss: 1.1917 - val_acc: 0.7760\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.7319 - acc: 0.9357 - val_loss: 1.1884 - val_acc: 0.7760\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.7363 - acc: 0.9500 - val_loss: 1.1850 - val_acc: 0.7800\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.7106 - acc: 0.9571 - val_loss: 1.1816 - val_acc: 0.7800\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.7164 - acc: 0.9571 - val_loss: 1.1782 - val_acc: 0.7820\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.7125 - acc: 0.9500 - val_loss: 1.1758 - val_acc: 0.7820\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.7311 - acc: 0.9571 - val_loss: 1.1733 - val_acc: 0.7800\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.7310 - acc: 0.9214 - val_loss: 1.1710 - val_acc: 0.7800\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.7359 - acc: 0.9429 - val_loss: 1.1694 - val_acc: 0.7820\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.7252 - acc: 0.9429 - val_loss: 1.1669 - val_acc: 0.7820\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.7088 - acc: 0.9643 - val_loss: 1.1635 - val_acc: 0.7820\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.7507 - acc: 0.9429 - val_loss: 1.1611 - val_acc: 0.7820\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.7196 - acc: 0.9571 - val_loss: 1.1592 - val_acc: 0.7820\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.6973 - acc: 0.9643 - val_loss: 1.1570 - val_acc: 0.7800\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.7250 - acc: 0.9286 - val_loss: 1.1544 - val_acc: 0.7800\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.7031 - acc: 0.9429 - val_loss: 1.1527 - val_acc: 0.7800\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.6752 - acc: 0.9643 - val_loss: 1.1508 - val_acc: 0.7800\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.7054 - acc: 0.9643 - val_loss: 1.1491 - val_acc: 0.7840\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.7203 - acc: 0.9571 - val_loss: 1.1474 - val_acc: 0.7860\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.7453 - acc: 0.9357 - val_loss: 1.1454 - val_acc: 0.7860\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.7138 - acc: 0.9643 - val_loss: 1.1436 - val_acc: 0.7840\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.7141 - acc: 0.9500 - val_loss: 1.1415 - val_acc: 0.7860\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.6203 - acc: 0.9571 - val_loss: 1.1390 - val_acc: 0.7860\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.6849 - acc: 0.9571 - val_loss: 1.1359 - val_acc: 0.7860\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.7233 - acc: 0.9286 - val_loss: 1.1328 - val_acc: 0.7860\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.6753 - acc: 0.9500 - val_loss: 1.1307 - val_acc: 0.7880\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.6796 - acc: 0.9786 - val_loss: 1.1286 - val_acc: 0.7880\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.7023 - acc: 0.9429 - val_loss: 1.1269 - val_acc: 0.7880\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 0.6993 - acc: 0.9286 - val_loss: 1.1255 - val_acc: 0.7880\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 292ms/step - loss: 0.6981 - acc: 0.9357 - val_loss: 1.1246 - val_acc: 0.7900\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 294ms/step - loss: 0.6652 - acc: 0.9714 - val_loss: 1.1238 - val_acc: 0.7880\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.6662 - acc: 0.9643 - val_loss: 1.1235 - val_acc: 0.7860\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.6890 - acc: 0.9643 - val_loss: 1.1232 - val_acc: 0.7880\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.6762 - acc: 0.9571 - val_loss: 1.1234 - val_acc: 0.7860\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.6927 - acc: 0.9286 - val_loss: 1.1242 - val_acc: 0.7880\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.6440 - acc: 0.9643 - val_loss: 1.1250 - val_acc: 0.7860\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.6858 - acc: 0.9714 - val_loss: 1.1253 - val_acc: 0.7860\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.6685 - acc: 0.9500 - val_loss: 1.1251 - val_acc: 0.7860\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.6863 - acc: 0.9286 - val_loss: 1.1238 - val_acc: 0.7860\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6539 - acc: 0.9500 - val_loss: 1.1225 - val_acc: 0.7860\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6696 - acc: 0.9571 - val_loss: 1.1204 - val_acc: 0.7860\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6803 - acc: 0.9643 - val_loss: 1.1177 - val_acc: 0.7860\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6215 - acc: 0.9786 - val_loss: 1.1150 - val_acc: 0.7840\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.6734 - acc: 0.9571 - val_loss: 1.1122 - val_acc: 0.7840\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6515 - acc: 0.9714 - val_loss: 1.1093 - val_acc: 0.7840\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6722 - acc: 0.9571 - val_loss: 1.1061 - val_acc: 0.7860\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6576 - acc: 0.9786 - val_loss: 1.1031 - val_acc: 0.7860\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6493 - acc: 0.9786 - val_loss: 1.1003 - val_acc: 0.7880\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5869 - acc: 0.9929 - val_loss: 1.0978 - val_acc: 0.7900\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6803 - acc: 0.9429 - val_loss: 1.0959 - val_acc: 0.7880\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.6425 - acc: 0.9571 - val_loss: 1.0942 - val_acc: 0.7880\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6096 - acc: 0.9714 - val_loss: 1.0924 - val_acc: 0.7880\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6133 - acc: 0.9643 - val_loss: 1.0906 - val_acc: 0.7880\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6383 - acc: 0.9571 - val_loss: 1.0890 - val_acc: 0.7880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2ca28b1570>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "uQRRTLCJf9hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=weights_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFCwoXVEf8n5",
        "outputId": "30919151-72e7-4a28-bffe-9c9411c56fa0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.0495 - acc: 0.8060\n",
            "Done.\n",
            "Test loss: 1.04948890209198\n",
            "Test accuracy: 0.8059999346733093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SimpleGCN Model"
      ],
      "metadata": {
        "id": "_6pUhyaXuQxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2  # Propagation steps for SGCN\n",
        "dataset = Citation(\"cora\", transforms=[LayerPreprocess(GCNConv), SGCN(K)])\n",
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr6n4azZuZOQ",
        "outputId": "31781c54-b91f-497e-ff74-75a2b25fcc51"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train model"
      ],
      "metadata": {
        "id": "WdOps-4Hz3OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_SGCN_text_classification(dataset, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Z1-05Hz78V",
        "outputId": "28c8c6f3-ded1-4288-d250-339cc28ad436"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 1433)]               0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 2708)]               0         []                            \n",
            "                                                                                                  \n",
            " gcn_conv_14 (GCNConv)       (None, 7)                    10031     ['input_5[0][0]',             \n",
            "                                                                     'input_6[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10031 (39.18 KB)\n",
            "Trainable params: 10031 (39.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjAEuG6XIAha",
        "outputId": "13cc4ca8-b1e0-4a2f-abfc-5e1a61d7b502"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1009 - acc: 0.1643 - val_loss: 0.3513 - val_acc: 0.3720\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0946 - acc: 0.6714 - val_loss: 0.3403 - val_acc: 0.5160\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0884 - acc: 0.9071 - val_loss: 0.3295 - val_acc: 0.6020\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0824 - acc: 0.9571 - val_loss: 0.3192 - val_acc: 0.6420\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0768 - acc: 0.9643 - val_loss: 0.3091 - val_acc: 0.6640\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0714 - acc: 0.9643 - val_loss: 0.2994 - val_acc: 0.6700\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0663 - acc: 0.9714 - val_loss: 0.2900 - val_acc: 0.6840\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0615 - acc: 0.9786 - val_loss: 0.2809 - val_acc: 0.6920\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0571 - acc: 0.9786 - val_loss: 0.2722 - val_acc: 0.7100\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0530 - acc: 0.9786 - val_loss: 0.2640 - val_acc: 0.7240\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0492 - acc: 0.9786 - val_loss: 0.2561 - val_acc: 0.7340\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0457 - acc: 0.9786 - val_loss: 0.2487 - val_acc: 0.7380\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0425 - acc: 0.9857 - val_loss: 0.2417 - val_acc: 0.7400\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0395 - acc: 0.9857 - val_loss: 0.2352 - val_acc: 0.7440\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0368 - acc: 0.9857 - val_loss: 0.2291 - val_acc: 0.7460\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0344 - acc: 0.9857 - val_loss: 0.2235 - val_acc: 0.7500\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0321 - acc: 0.9857 - val_loss: 0.2183 - val_acc: 0.7580\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0301 - acc: 0.9857 - val_loss: 0.2135 - val_acc: 0.7540\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0283 - acc: 0.9857 - val_loss: 0.2092 - val_acc: 0.7520\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0266 - acc: 0.9857 - val_loss: 0.2051 - val_acc: 0.7560\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0251 - acc: 0.9857 - val_loss: 0.2014 - val_acc: 0.7560\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0237 - acc: 0.9857 - val_loss: 0.1981 - val_acc: 0.7560\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0224 - acc: 0.9857 - val_loss: 0.1950 - val_acc: 0.7560\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0213 - acc: 0.9857 - val_loss: 0.1922 - val_acc: 0.7580\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0202 - acc: 0.9857 - val_loss: 0.1896 - val_acc: 0.7560\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0193 - acc: 0.9857 - val_loss: 0.1872 - val_acc: 0.7580\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0184 - acc: 0.9857 - val_loss: 0.1851 - val_acc: 0.7600\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0176 - acc: 0.9929 - val_loss: 0.1831 - val_acc: 0.7600\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0169 - acc: 0.9929 - val_loss: 0.1814 - val_acc: 0.7620\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0162 - acc: 0.9929 - val_loss: 0.1797 - val_acc: 0.7600\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0156 - acc: 0.9929 - val_loss: 0.1782 - val_acc: 0.7600\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1769 - val_acc: 0.7600\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1756 - val_acc: 0.7640\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1745 - val_acc: 0.7640\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.7580\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.7600\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.7600\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1708 - val_acc: 0.7580\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.7600\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 0.7580\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.7580\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.7600\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.7600\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.7600\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.7600\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.7600\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1656 - val_acc: 0.7600\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.7580\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 0.7560\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.1644 - val_acc: 0.7560\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.1641 - val_acc: 0.7560\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.1638 - val_acc: 0.7520\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 0.7520\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.1632 - val_acc: 0.7520\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1629 - val_acc: 0.7520\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.1626 - val_acc: 0.7520\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1624 - val_acc: 0.7500\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 0.7520\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.7520\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.1617 - val_acc: 0.7500\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.7500\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.7500\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.7500\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.7480\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.7480\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.7480\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.7480\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1600 - val_acc: 0.7480\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.7480\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.7460\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.7460\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1593 - val_acc: 0.7460\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.7480\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.7500\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.7500\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.7500\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.7500\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.7500\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.7500\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.7500\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.7480\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.7480\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1576 - val_acc: 0.7480\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.7480\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.7480\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.7480\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.7480\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.7480\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.7500\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.7480\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.7480\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.7480\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.7480\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.7480\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.7480\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.7480\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.7500\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1559 - val_acc: 0.7480\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 0.7480\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.7480\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.7480\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.7500\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.7500\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.7500\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.7520\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.7520\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.7520\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 0.7540\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.7540\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.7540\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.7540\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.7540\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1545 - val_acc: 0.7520\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1544 - val_acc: 0.7560\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.1543 - val_acc: 0.7560\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1542 - val_acc: 0.7560\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 0.7560\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.7560\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.7560\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1539 - val_acc: 0.7560\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1538 - val_acc: 0.7560\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1537 - val_acc: 0.7560\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1536 - val_acc: 0.7560\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.7560\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 0.7560\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1534 - val_acc: 0.7560\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 0.7560\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 0.7560\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1531 - val_acc: 0.7560\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1531 - val_acc: 0.7560\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1530 - val_acc: 0.7560\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.1529 - val_acc: 0.7560\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1528 - val_acc: 0.7560\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.7560\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 0.7560\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1526 - val_acc: 0.7560\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1525 - val_acc: 0.7560\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1524 - val_acc: 0.7560\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1524 - val_acc: 0.7560\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 0.7560\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1522 - val_acc: 0.7580\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.7580\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 0.7580\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1520 - val_acc: 0.7580\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1519 - val_acc: 0.7580\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1518 - val_acc: 0.7580\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1518 - val_acc: 0.7580\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1517 - val_acc: 0.7580\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.7580\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1516 - val_acc: 0.7580\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1515 - val_acc: 0.7580\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.7580\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.7580\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1513 - val_acc: 0.7580\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1512 - val_acc: 0.7580\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1511 - val_acc: 0.7580\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1511 - val_acc: 0.7580\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.7580\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1509 - val_acc: 0.7580\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1509 - val_acc: 0.7580\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1508 - val_acc: 0.7580\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.7580\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.7580\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1506 - val_acc: 0.7580\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.7580\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.7580\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.7580\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.7580\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1503 - val_acc: 0.7580\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1502 - val_acc: 0.7580\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.7580\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1501 - val_acc: 0.7580\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 0.7580\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 0.7580\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 0.7580\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.7580\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 0.7580\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1497 - val_acc: 0.7580\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.7580\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 0.7580\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.7580\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 0.7580\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.7580\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.7580\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 0.7580\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 0.7580\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 0.7600\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.7600\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1491 - val_acc: 0.7600\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 0.7600\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.7600\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.7600\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1488 - val_acc: 0.7600\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1488 - val_acc: 0.7600\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.7600\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1487 - val_acc: 0.7600\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 0.7600\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.7600\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.7600\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.1484 - val_acc: 0.7600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2cb0e6a050>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "oR8eh-ywz8eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmsJZPeb0IlW",
        "outputId": "553c697b-eb34-432f-8c08-6679a2b03dd3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.2652 - acc: 0.7840\n",
            "Done.\n",
            "Test loss: 0.26516053080558777\n",
            "Test accuracy: 0.7839999794960022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Citeseer"
      ],
      "metadata": {
        "id": "cB_Q0pu9dco-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "seed = 0\n",
        "epochs = 200\n",
        "patience = 10\n",
        "data = \"citeseer\"\n",
        "tf.random.set_seed(seed=seed)"
      ],
      "metadata": {
        "id": "zwCq-ldi2F88"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN Model"
      ],
      "metadata": {
        "id": "coVvBe9p4JfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Citation(data, normalize_x=True, transforms=[LayerPreprocess(GCNConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcdeyTAm2KpR",
        "outputId": "69b016fb-4e33-482b-a04d-2af59c5080cd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spektral/datasets/citation.py:194: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model"
      ],
      "metadata": {
        "id": "gnhkyFEE4JfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, weights_tr, weights_va, weights_te = create_GCN_text_classification(dataset, learning_rate)\n",
        "loader_tr = SingleLoader(dataset, sample_weights=weights_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87b2d57-d856-4a74-855c-568ab1048e1d",
        "id": "7cy9YeFv4JfR"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.7995 - acc: 0.2167 - val_loss: 1.7955 - val_acc: 0.4800\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 1s 534ms/step - loss: 1.7932 - acc: 0.5250 - val_loss: 1.7919 - val_acc: 0.5300\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.7874 - acc: 0.6667 - val_loss: 1.7889 - val_acc: 0.5200\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 1.7810 - acc: 0.7167 - val_loss: 1.7866 - val_acc: 0.5380\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 1.7736 - acc: 0.7333 - val_loss: 1.7848 - val_acc: 0.5500\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 1.7677 - acc: 0.7667 - val_loss: 1.7831 - val_acc: 0.5660\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 442ms/step - loss: 1.7601 - acc: 0.8000 - val_loss: 1.7815 - val_acc: 0.5900\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 1.7574 - acc: 0.8167 - val_loss: 1.7799 - val_acc: 0.6100\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 1.7473 - acc: 0.8583 - val_loss: 1.7783 - val_acc: 0.6140\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 1s 570ms/step - loss: 1.7410 - acc: 0.8167 - val_loss: 1.7767 - val_acc: 0.6220\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.7336 - acc: 0.8083 - val_loss: 1.7750 - val_acc: 0.6300\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 1.7235 - acc: 0.8750 - val_loss: 1.7733 - val_acc: 0.6320\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 1.7174 - acc: 0.8500 - val_loss: 1.7716 - val_acc: 0.6340\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 1.7146 - acc: 0.8583 - val_loss: 1.7699 - val_acc: 0.6360\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 1.6982 - acc: 0.8667 - val_loss: 1.7683 - val_acc: 0.6340\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.6964 - acc: 0.8583 - val_loss: 1.7665 - val_acc: 0.6340\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 1.6816 - acc: 0.9000 - val_loss: 1.7648 - val_acc: 0.6320\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 1.6801 - acc: 0.8750 - val_loss: 1.7630 - val_acc: 0.6320\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.6623 - acc: 0.8583 - val_loss: 1.7611 - val_acc: 0.6300\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.6595 - acc: 0.8500 - val_loss: 1.7591 - val_acc: 0.6320\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 1.6584 - acc: 0.8583 - val_loss: 1.7571 - val_acc: 0.6340\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 1.6386 - acc: 0.8750 - val_loss: 1.7550 - val_acc: 0.6340\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.6283 - acc: 0.9000 - val_loss: 1.7529 - val_acc: 0.6400\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 1.6092 - acc: 0.9000 - val_loss: 1.7506 - val_acc: 0.6460\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.6062 - acc: 0.8583 - val_loss: 1.7483 - val_acc: 0.6460\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.6086 - acc: 0.8667 - val_loss: 1.7459 - val_acc: 0.6520\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.6017 - acc: 0.9000 - val_loss: 1.7435 - val_acc: 0.6440\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.5902 - acc: 0.8750 - val_loss: 1.7409 - val_acc: 0.6500\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.5859 - acc: 0.8667 - val_loss: 1.7383 - val_acc: 0.6520\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 1.5654 - acc: 0.8250 - val_loss: 1.7356 - val_acc: 0.6580\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.5415 - acc: 0.8833 - val_loss: 1.7329 - val_acc: 0.6600\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.5477 - acc: 0.9000 - val_loss: 1.7301 - val_acc: 0.6620\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 1.5255 - acc: 0.8833 - val_loss: 1.7272 - val_acc: 0.6600\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 350ms/step - loss: 1.4988 - acc: 0.8917 - val_loss: 1.7242 - val_acc: 0.6620\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 1.4991 - acc: 0.9083 - val_loss: 1.7209 - val_acc: 0.6600\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 1.4879 - acc: 0.8917 - val_loss: 1.7176 - val_acc: 0.6640\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 432ms/step - loss: 1.4675 - acc: 0.9083 - val_loss: 1.7141 - val_acc: 0.6680\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 1.4713 - acc: 0.8500 - val_loss: 1.7106 - val_acc: 0.6680\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 1.4818 - acc: 0.8833 - val_loss: 1.7070 - val_acc: 0.6640\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 300ms/step - loss: 1.4396 - acc: 0.8500 - val_loss: 1.7035 - val_acc: 0.6660\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 1.4352 - acc: 0.8833 - val_loss: 1.7000 - val_acc: 0.6660\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 1.4199 - acc: 0.8917 - val_loss: 1.6964 - val_acc: 0.6660\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 1.3965 - acc: 0.9000 - val_loss: 1.6928 - val_acc: 0.6640\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 1.3880 - acc: 0.9083 - val_loss: 1.6891 - val_acc: 0.6640\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 1.3963 - acc: 0.8833 - val_loss: 1.6854 - val_acc: 0.6640\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.3697 - acc: 0.9000 - val_loss: 1.6817 - val_acc: 0.6660\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.3922 - acc: 0.8833 - val_loss: 1.6780 - val_acc: 0.6660\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.3723 - acc: 0.9000 - val_loss: 1.6741 - val_acc: 0.6680\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.3285 - acc: 0.9167 - val_loss: 1.6703 - val_acc: 0.6680\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 1.3366 - acc: 0.9083 - val_loss: 1.6665 - val_acc: 0.6640\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 1.3490 - acc: 0.8833 - val_loss: 1.6626 - val_acc: 0.6640\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 1.3202 - acc: 0.9000 - val_loss: 1.6588 - val_acc: 0.6640\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 1.3147 - acc: 0.8583 - val_loss: 1.6551 - val_acc: 0.6620\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.2958 - acc: 0.8833 - val_loss: 1.6516 - val_acc: 0.6640\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 1.2516 - acc: 0.8750 - val_loss: 1.6483 - val_acc: 0.6660\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.2514 - acc: 0.9083 - val_loss: 1.6450 - val_acc: 0.6660\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.2368 - acc: 0.8917 - val_loss: 1.6417 - val_acc: 0.6640\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.2456 - acc: 0.9000 - val_loss: 1.6381 - val_acc: 0.6640\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 1.2098 - acc: 0.9083 - val_loss: 1.6343 - val_acc: 0.6680\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 1.2339 - acc: 0.9167 - val_loss: 1.6306 - val_acc: 0.6680\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.2097 - acc: 0.9250 - val_loss: 1.6270 - val_acc: 0.6740\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.1950 - acc: 0.9167 - val_loss: 1.6232 - val_acc: 0.6720\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.1676 - acc: 0.9250 - val_loss: 1.6196 - val_acc: 0.6740\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 1.1897 - acc: 0.8917 - val_loss: 1.6160 - val_acc: 0.6740\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 1.1714 - acc: 0.8833 - val_loss: 1.6126 - val_acc: 0.6780\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.1401 - acc: 0.9000 - val_loss: 1.6093 - val_acc: 0.6800\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 1.1511 - acc: 0.9167 - val_loss: 1.6060 - val_acc: 0.6820\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 1.1841 - acc: 0.9333 - val_loss: 1.6027 - val_acc: 0.6840\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 1.1419 - acc: 0.9167 - val_loss: 1.5992 - val_acc: 0.6840\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.0884 - acc: 0.9417 - val_loss: 1.5957 - val_acc: 0.6820\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 1.1090 - acc: 0.9000 - val_loss: 1.5921 - val_acc: 0.6820\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.0874 - acc: 0.9000 - val_loss: 1.5885 - val_acc: 0.6820\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.0908 - acc: 0.8917 - val_loss: 1.5849 - val_acc: 0.6820\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 1.1277 - acc: 0.9000 - val_loss: 1.5813 - val_acc: 0.6820\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.0702 - acc: 0.9250 - val_loss: 1.5778 - val_acc: 0.6820\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 1.0842 - acc: 0.9167 - val_loss: 1.5743 - val_acc: 0.6840\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 1.0782 - acc: 0.9083 - val_loss: 1.5706 - val_acc: 0.6860\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 1.0941 - acc: 0.9083 - val_loss: 1.5668 - val_acc: 0.6860\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.1091 - acc: 0.9250 - val_loss: 1.5629 - val_acc: 0.6860\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.0874 - acc: 0.9167 - val_loss: 1.5590 - val_acc: 0.6820\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.0418 - acc: 0.8917 - val_loss: 1.5552 - val_acc: 0.6820\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 1.0598 - acc: 0.9167 - val_loss: 1.5513 - val_acc: 0.6860\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 1.0390 - acc: 0.9167 - val_loss: 1.5475 - val_acc: 0.6860\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 1.0295 - acc: 0.9333 - val_loss: 1.5439 - val_acc: 0.6880\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 1.0559 - acc: 0.9000 - val_loss: 1.5405 - val_acc: 0.6880\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 1.0247 - acc: 0.9250 - val_loss: 1.5370 - val_acc: 0.6880\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 325ms/step - loss: 0.9932 - acc: 0.9083 - val_loss: 1.5336 - val_acc: 0.6900\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.9919 - acc: 0.9167 - val_loss: 1.5302 - val_acc: 0.6900\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.9870 - acc: 0.9333 - val_loss: 1.5266 - val_acc: 0.6900\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 1.0122 - acc: 0.8833 - val_loss: 1.5231 - val_acc: 0.6920\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.9927 - acc: 0.9083 - val_loss: 1.5195 - val_acc: 0.6920\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 0.9624 - acc: 0.9250 - val_loss: 1.5161 - val_acc: 0.6920\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.9877 - acc: 0.9500 - val_loss: 1.5128 - val_acc: 0.6920\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.9616 - acc: 0.9417 - val_loss: 1.5096 - val_acc: 0.6920\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.9850 - acc: 0.9333 - val_loss: 1.5065 - val_acc: 0.6920\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.9631 - acc: 0.9083 - val_loss: 1.5031 - val_acc: 0.6920\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.9659 - acc: 0.9250 - val_loss: 1.5000 - val_acc: 0.6920\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.9609 - acc: 0.9250 - val_loss: 1.4970 - val_acc: 0.6920\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.9567 - acc: 0.9250 - val_loss: 1.4942 - val_acc: 0.6920\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.9134 - acc: 0.9250 - val_loss: 1.4913 - val_acc: 0.6900\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.9159 - acc: 0.9333 - val_loss: 1.4885 - val_acc: 0.6900\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.9500 - acc: 0.9417 - val_loss: 1.4855 - val_acc: 0.6920\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.8935 - acc: 0.9667 - val_loss: 1.4825 - val_acc: 0.6940\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.8974 - acc: 0.9417 - val_loss: 1.4792 - val_acc: 0.6940\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.9576 - acc: 0.9417 - val_loss: 1.4760 - val_acc: 0.6940\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.9248 - acc: 0.9083 - val_loss: 1.4730 - val_acc: 0.6940\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.9008 - acc: 0.9500 - val_loss: 1.4701 - val_acc: 0.6940\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.8984 - acc: 0.9250 - val_loss: 1.4673 - val_acc: 0.6940\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.8892 - acc: 0.9417 - val_loss: 1.4645 - val_acc: 0.6940\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.9142 - acc: 0.9417 - val_loss: 1.4619 - val_acc: 0.6940\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.8719 - acc: 0.9250 - val_loss: 1.4591 - val_acc: 0.6940\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.8987 - acc: 0.9167 - val_loss: 1.4563 - val_acc: 0.6940\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8688 - acc: 0.9583 - val_loss: 1.4536 - val_acc: 0.6920\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8660 - acc: 0.9583 - val_loss: 1.4511 - val_acc: 0.6940\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.8637 - acc: 0.9333 - val_loss: 1.4488 - val_acc: 0.6940\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.9100 - acc: 0.9417 - val_loss: 1.4466 - val_acc: 0.6940\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.8727 - acc: 0.9417 - val_loss: 1.4447 - val_acc: 0.6940\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.8934 - acc: 0.9083 - val_loss: 1.4424 - val_acc: 0.6940\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.8928 - acc: 0.9333 - val_loss: 1.4401 - val_acc: 0.6960\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.9040 - acc: 0.9083 - val_loss: 1.4383 - val_acc: 0.6960\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.8521 - acc: 0.9083 - val_loss: 1.4365 - val_acc: 0.6960\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.8629 - acc: 0.9167 - val_loss: 1.4346 - val_acc: 0.6960\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.9002 - acc: 0.9250 - val_loss: 1.4323 - val_acc: 0.6940\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8333 - acc: 0.9333 - val_loss: 1.4302 - val_acc: 0.6960\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.8533 - acc: 0.9333 - val_loss: 1.4281 - val_acc: 0.6960\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.8090 - acc: 0.9333 - val_loss: 1.4262 - val_acc: 0.6960\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.8916 - acc: 0.9167 - val_loss: 1.4242 - val_acc: 0.6940\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.8602 - acc: 0.9083 - val_loss: 1.4220 - val_acc: 0.6940\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.8586 - acc: 0.9250 - val_loss: 1.4200 - val_acc: 0.6940\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.8709 - acc: 0.9250 - val_loss: 1.4181 - val_acc: 0.6940\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.8179 - acc: 0.9500 - val_loss: 1.4163 - val_acc: 0.6940\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.8047 - acc: 0.9333 - val_loss: 1.4146 - val_acc: 0.6940\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8166 - acc: 0.9417 - val_loss: 1.4124 - val_acc: 0.6940\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.8075 - acc: 0.9667 - val_loss: 1.4100 - val_acc: 0.6940\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.8334 - acc: 0.9417 - val_loss: 1.4076 - val_acc: 0.6960\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.7694 - acc: 0.9667 - val_loss: 1.4053 - val_acc: 0.6960\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.8205 - acc: 0.9500 - val_loss: 1.4030 - val_acc: 0.6960\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.8282 - acc: 0.9500 - val_loss: 1.4012 - val_acc: 0.7000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.8019 - acc: 0.9500 - val_loss: 1.3996 - val_acc: 0.7000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.8228 - acc: 0.9333 - val_loss: 1.3981 - val_acc: 0.7000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7721 - acc: 0.9583 - val_loss: 1.3961 - val_acc: 0.7000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.7952 - acc: 0.9583 - val_loss: 1.3940 - val_acc: 0.7020\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.8092 - acc: 0.9333 - val_loss: 1.3921 - val_acc: 0.7020\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 447ms/step - loss: 0.8188 - acc: 0.9000 - val_loss: 1.3903 - val_acc: 0.7020\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.8185 - acc: 0.9083 - val_loss: 1.3887 - val_acc: 0.7040\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 412ms/step - loss: 0.7638 - acc: 0.9583 - val_loss: 1.3872 - val_acc: 0.7040\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 404ms/step - loss: 0.8175 - acc: 0.9250 - val_loss: 1.3858 - val_acc: 0.7060\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 398ms/step - loss: 0.7642 - acc: 0.9667 - val_loss: 1.3847 - val_acc: 0.7060\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.7846 - acc: 0.9583 - val_loss: 1.3836 - val_acc: 0.7040\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.7960 - acc: 0.9417 - val_loss: 1.3825 - val_acc: 0.7040\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7940 - acc: 0.9667 - val_loss: 1.3814 - val_acc: 0.7060\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7841 - acc: 0.9167 - val_loss: 1.3799 - val_acc: 0.7060\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7729 - acc: 0.9333 - val_loss: 1.3785 - val_acc: 0.7060\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.7312 - acc: 0.9417 - val_loss: 1.3766 - val_acc: 0.7080\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.7658 - acc: 0.9333 - val_loss: 1.3744 - val_acc: 0.7080\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.7687 - acc: 0.9333 - val_loss: 1.3720 - val_acc: 0.7080\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.7928 - acc: 0.9417 - val_loss: 1.3701 - val_acc: 0.7100\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7121 - acc: 0.9333 - val_loss: 1.3682 - val_acc: 0.7060\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.7443 - acc: 0.9750 - val_loss: 1.3664 - val_acc: 0.7040\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7227 - acc: 0.9833 - val_loss: 1.3646 - val_acc: 0.7040\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.7567 - acc: 0.9417 - val_loss: 1.3624 - val_acc: 0.7040\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.7525 - acc: 0.9417 - val_loss: 1.3603 - val_acc: 0.7060\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.7598 - acc: 0.9417 - val_loss: 1.3584 - val_acc: 0.7060\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.7724 - acc: 0.9417 - val_loss: 1.3563 - val_acc: 0.7060\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7204 - acc: 0.9500 - val_loss: 1.3543 - val_acc: 0.7080\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.7730 - acc: 0.9250 - val_loss: 1.3522 - val_acc: 0.7080\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.7502 - acc: 0.9417 - val_loss: 1.3506 - val_acc: 0.7060\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.7482 - acc: 0.9417 - val_loss: 1.3495 - val_acc: 0.7060\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7799 - acc: 0.9167 - val_loss: 1.3485 - val_acc: 0.7060\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7269 - acc: 0.9500 - val_loss: 1.3473 - val_acc: 0.7040\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7231 - acc: 0.9500 - val_loss: 1.3459 - val_acc: 0.7040\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.7420 - acc: 0.9583 - val_loss: 1.3448 - val_acc: 0.7040\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.7326 - acc: 0.9250 - val_loss: 1.3439 - val_acc: 0.7040\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.7249 - acc: 0.9583 - val_loss: 1.3431 - val_acc: 0.7040\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7341 - acc: 0.9500 - val_loss: 1.3424 - val_acc: 0.7040\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.7680 - acc: 0.9167 - val_loss: 1.3412 - val_acc: 0.7040\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.6933 - acc: 0.9250 - val_loss: 1.3402 - val_acc: 0.7060\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.6817 - acc: 0.9500 - val_loss: 1.3394 - val_acc: 0.7060\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.7425 - acc: 0.9167 - val_loss: 1.3384 - val_acc: 0.7060\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.7356 - acc: 0.9417 - val_loss: 1.3372 - val_acc: 0.7100\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.7033 - acc: 0.9250 - val_loss: 1.3358 - val_acc: 0.7100\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.6931 - acc: 0.9583 - val_loss: 1.3348 - val_acc: 0.7100\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.7077 - acc: 0.9500 - val_loss: 1.3342 - val_acc: 0.7100\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.7459 - acc: 0.9500 - val_loss: 1.3341 - val_acc: 0.7100\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.7337 - acc: 0.9417 - val_loss: 1.3340 - val_acc: 0.7040\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.7272 - acc: 0.9583 - val_loss: 1.3343 - val_acc: 0.7020\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6495 - acc: 0.9833 - val_loss: 1.3346 - val_acc: 0.7020\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6910 - acc: 0.9583 - val_loss: 1.3342 - val_acc: 0.6980\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.6885 - acc: 0.9333 - val_loss: 1.3334 - val_acc: 0.7000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.6690 - acc: 0.9417 - val_loss: 1.3323 - val_acc: 0.7000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.7439 - acc: 0.9417 - val_loss: 1.3311 - val_acc: 0.7020\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.6917 - acc: 0.9583 - val_loss: 1.3295 - val_acc: 0.7020\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 299ms/step - loss: 0.6905 - acc: 0.9500 - val_loss: 1.3274 - val_acc: 0.7020\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 317ms/step - loss: 0.6774 - acc: 0.9417 - val_loss: 1.3252 - val_acc: 0.7020\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 0.6719 - acc: 0.9583 - val_loss: 1.3226 - val_acc: 0.7040\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.6871 - acc: 0.9750 - val_loss: 1.3198 - val_acc: 0.7060\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 408ms/step - loss: 0.7233 - acc: 0.9500 - val_loss: 1.3168 - val_acc: 0.7020\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 409ms/step - loss: 0.6521 - acc: 0.9417 - val_loss: 1.3140 - val_acc: 0.7080\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 0.7026 - acc: 0.9500 - val_loss: 1.3117 - val_acc: 0.7080\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.6939 - acc: 0.9583 - val_loss: 1.3096 - val_acc: 0.7080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2cb0c67dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "1UXj4uW_4JfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=weights_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496f24f0-5856-4632-e49b-4bf495819171",
        "id": "DXTeU6Dt4JfR"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.2878 - acc: 0.7070\n",
            "Done.\n",
            "Test loss: 1.287792682647705\n",
            "Test accuracy: 0.7070000171661377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplify GCN Model"
      ],
      "metadata": {
        "id": "64MBNkbKNusO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2  # Propagation steps for SGCN\n",
        "dataset = Citation(\"citeseer\", transforms=[LayerPreprocess(GCNConv), SGCN(K)])\n",
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8322ce3a-2f19-4c80-ab04-77b495fda9c7",
        "id": "NXnQIdEzNusP"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train model"
      ],
      "metadata": {
        "id": "7ILYd-QdNusQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_SGCN_text_classification(dataset, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01531d4a-6090-4537-ef80-ef75bd0bf8df",
        "id": "jLw8OcbONusR"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 3703)]               0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 3327)]               0         []                            \n",
            "                                                                                                  \n",
            " gcn_conv_17 (GCNConv)       (None, 6)                    22218     ['input_7[0][0]',             \n",
            "                                                                     'input_8[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22218 (86.79 KB)\n",
            "Trainable params: 22218 (86.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d055f6-e5ac-41d1-d190-431edc9072b9",
        "id": "NUbxgHS5NusR"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.0653 - acc: 0.1167 - val_loss: 0.2595 - val_acc: 0.4400\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0573 - acc: 0.8583 - val_loss: 0.2484 - val_acc: 0.5900\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0498 - acc: 0.9500 - val_loss: 0.2378 - val_acc: 0.6360\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0430 - acc: 0.9500 - val_loss: 0.2279 - val_acc: 0.6380\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0370 - acc: 0.9500 - val_loss: 0.2187 - val_acc: 0.6500\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0318 - acc: 0.9500 - val_loss: 0.2103 - val_acc: 0.6480\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0273 - acc: 0.9500 - val_loss: 0.2027 - val_acc: 0.6560\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0236 - acc: 0.9583 - val_loss: 0.1959 - val_acc: 0.6660\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0204 - acc: 0.9583 - val_loss: 0.1900 - val_acc: 0.6640\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0178 - acc: 0.9667 - val_loss: 0.1849 - val_acc: 0.6720\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0156 - acc: 0.9833 - val_loss: 0.1805 - val_acc: 0.6760\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0138 - acc: 0.9833 - val_loss: 0.1769 - val_acc: 0.6760\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0123 - acc: 0.9833 - val_loss: 0.1738 - val_acc: 0.6800\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0111 - acc: 0.9833 - val_loss: 0.1712 - val_acc: 0.6820\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0101 - acc: 0.9833 - val_loss: 0.1691 - val_acc: 0.6780\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0092 - acc: 0.9833 - val_loss: 0.1674 - val_acc: 0.6820\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0085 - acc: 0.9833 - val_loss: 0.1660 - val_acc: 0.6780\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0079 - acc: 0.9833 - val_loss: 0.1649 - val_acc: 0.6760\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0074 - acc: 0.9833 - val_loss: 0.1641 - val_acc: 0.6740\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0070 - acc: 0.9917 - val_loss: 0.1634 - val_acc: 0.6700\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0067 - acc: 0.9917 - val_loss: 0.1629 - val_acc: 0.6680\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 0.6660\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1622 - val_acc: 0.6660\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1619 - val_acc: 0.6640\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.6620\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1616 - val_acc: 0.6600\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.6600\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1615 - val_acc: 0.6580\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1614 - val_acc: 0.6520\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.6540\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.6540\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.6560\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6540\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6520\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6560\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6560\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6560\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6540\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6520\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6480\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6480\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6460\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6480\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6480\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6480\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6500\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6500\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6500\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1612 - val_acc: 0.6500\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.6500\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.6520\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.6440\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.6440\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1611 - val_acc: 0.6440\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.6440\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.6440\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.6440\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1610 - val_acc: 0.6440\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.6440\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.6440\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1609 - val_acc: 0.6440\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.6440\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.6440\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1608 - val_acc: 0.6440\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.6480\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1607 - val_acc: 0.6480\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.6460\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.6440\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.6460\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 0.6460\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.6460\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1604 - val_acc: 0.6460\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.6460\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1603 - val_acc: 0.6460\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 0.6480\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 0.6480\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 0.6480\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1600 - val_acc: 0.6480\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.6480\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.6480\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.6480\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1598 - val_acc: 0.6480\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1597 - val_acc: 0.6480\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.6480\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1596 - val_acc: 0.6480\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.6480\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 0.6480\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 0.6480\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1593 - val_acc: 0.6500\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1593 - val_acc: 0.6500\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.6460\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.6460\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.6460\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1591 - val_acc: 0.6460\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.6460\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1590 - val_acc: 0.6460\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.6460\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 0.6480\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.6480\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 0.6480\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1587 - val_acc: 0.6480\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.6480\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1586 - val_acc: 0.6440\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1585 - val_acc: 0.6440\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1585 - val_acc: 0.6440\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.6440\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1584 - val_acc: 0.6440\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.6440\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1583 - val_acc: 0.6440\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.6440\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 0.6440\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.6440\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.6440\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 0.6440\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.6440\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1580 - val_acc: 0.6420\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.6420\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.6420\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1578 - val_acc: 0.6420\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1578 - val_acc: 0.6420\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.6420\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1577 - val_acc: 0.6440\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1576 - val_acc: 0.6440\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1576 - val_acc: 0.6440\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.6440\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.6440\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.6440\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.6440\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1574 - val_acc: 0.6440\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.6460\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 0.6460\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.6460\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1572 - val_acc: 0.6460\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.6460\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1571 - val_acc: 0.6460\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.6460\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1570 - val_acc: 0.6460\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.6460\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.6460\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.6460\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.6460\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1568 - val_acc: 0.6460\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.6460\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1567 - val_acc: 0.6460\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.6460\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.6460\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.6460\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.6460\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 0.6460\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.6500\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.6500\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1564 - val_acc: 0.6500\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.6500\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1563 - val_acc: 0.6500\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.6500\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.6520\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.6540\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.6540\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 0.6540\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.6540\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.6540\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1560 - val_acc: 0.6540\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1559 - val_acc: 0.6540\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1559 - val_acc: 0.6540\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 0.6540\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 0.6540\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1558 - val_acc: 0.6540\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.6540\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1557 - val_acc: 0.6540\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.6540\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.6540\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.6540\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.6540\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.6540\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 0.6540\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.6540\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 0.6540\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.6540\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.6540\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1553 - val_acc: 0.6540\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.6540\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.6560\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.6560\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.6580\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.6580\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 0.6580\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.6580\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.6580\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1550 - val_acc: 0.6600\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 0.6620\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 0.6620\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.6620\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.6620\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1548 - val_acc: 0.6640\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.6640\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.6640\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1547 - val_acc: 0.6620\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.6640\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.6640\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1546 - val_acc: 0.6640\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2cb396ee60>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "RS3GiGwxNusR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfd12bc-7521-4dee-da1a-1f7c2813e927",
        "id": "kDW2uTAfNusR"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3097 - acc: 0.6630\n",
            "Done.\n",
            "Test loss: 0.3096916973590851\n",
            "Test accuracy: 0.6629999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pubmed"
      ],
      "metadata": {
        "id": "ESV1XDrFdhYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-2\n",
        "seed = 0\n",
        "epochs = 200\n",
        "patience = 10\n",
        "data = \"pubmed\"\n",
        "tf.random.set_seed(seed=seed)"
      ],
      "metadata": {
        "id": "puHL6IMT25lU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCN Model"
      ],
      "metadata": {
        "id": "5mhyf5Lw4Pwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Citation(data, normalize_x=True, transforms=[LayerPreprocess(GCNConv)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC3o-tU029ik",
        "outputId": "838c49e1-a6a7-405c-f6ad-976906b12696"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing node features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Model"
      ],
      "metadata": {
        "id": "HRYq5R9P4Pwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, weights_tr, weights_va, weights_te = create_GCN_text_classification(dataset, learning_rate)\n",
        "loader_tr = SingleLoader(dataset, sample_weights=weights_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=weights_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a527fb12-be23-4d11-8222-bb55291b84d4",
        "id": "4Z-NZV084Pwi"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1053 - acc: 0.4167 - val_loss: 1.1031 - val_acc: 0.6200\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 1.1022 - acc: 0.6167 - val_loss: 1.1001 - val_acc: 0.6900\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0964 - acc: 0.8000 - val_loss: 1.0967 - val_acc: 0.7220\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 1.0910 - acc: 0.8667 - val_loss: 1.0930 - val_acc: 0.7300\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 1.0829 - acc: 0.8667 - val_loss: 1.0891 - val_acc: 0.7440\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 1.0783 - acc: 0.8167 - val_loss: 1.0850 - val_acc: 0.7440\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 1.0681 - acc: 0.8500 - val_loss: 1.0807 - val_acc: 0.7340\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 1.0620 - acc: 0.8667 - val_loss: 1.0764 - val_acc: 0.7260\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 1.0577 - acc: 0.8500 - val_loss: 1.0720 - val_acc: 0.7300\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 1.0506 - acc: 0.8833 - val_loss: 1.0676 - val_acc: 0.7280\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 1.0426 - acc: 0.8500 - val_loss: 1.0631 - val_acc: 0.7280\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 1.0302 - acc: 0.8833 - val_loss: 1.0585 - val_acc: 0.7340\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 1.0140 - acc: 0.8667 - val_loss: 1.0538 - val_acc: 0.7340\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 1.0108 - acc: 0.9167 - val_loss: 1.0490 - val_acc: 0.7360\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.9996 - acc: 0.8833 - val_loss: 1.0440 - val_acc: 0.7360\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.9890 - acc: 0.8667 - val_loss: 1.0389 - val_acc: 0.7380\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.9832 - acc: 0.9333 - val_loss: 1.0338 - val_acc: 0.7400\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.9643 - acc: 0.9167 - val_loss: 1.0287 - val_acc: 0.7400\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.9558 - acc: 0.9167 - val_loss: 1.0235 - val_acc: 0.7420\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.9550 - acc: 0.8667 - val_loss: 1.0183 - val_acc: 0.7440\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.9481 - acc: 0.8500 - val_loss: 1.0130 - val_acc: 0.7440\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.9457 - acc: 0.8500 - val_loss: 1.0078 - val_acc: 0.7420\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.9035 - acc: 0.9333 - val_loss: 1.0025 - val_acc: 0.7420\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.8983 - acc: 0.8667 - val_loss: 0.9972 - val_acc: 0.7440\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.9006 - acc: 0.9333 - val_loss: 0.9918 - val_acc: 0.7440\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.8900 - acc: 0.9333 - val_loss: 0.9862 - val_acc: 0.7460\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.8588 - acc: 0.9167 - val_loss: 0.9807 - val_acc: 0.7500\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.8677 - acc: 0.9333 - val_loss: 0.9751 - val_acc: 0.7480\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.8620 - acc: 0.9000 - val_loss: 0.9695 - val_acc: 0.7520\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.8506 - acc: 0.9167 - val_loss: 0.9639 - val_acc: 0.7580\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8393 - acc: 0.9167 - val_loss: 0.9583 - val_acc: 0.7580\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.8415 - acc: 0.9000 - val_loss: 0.9526 - val_acc: 0.7580\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.8147 - acc: 0.9333 - val_loss: 0.9466 - val_acc: 0.7600\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.7840 - acc: 0.9500 - val_loss: 0.9408 - val_acc: 0.7620\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.8036 - acc: 0.9167 - val_loss: 0.9351 - val_acc: 0.7680\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.7604 - acc: 0.9500 - val_loss: 0.9295 - val_acc: 0.7680\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.7739 - acc: 0.9500 - val_loss: 0.9240 - val_acc: 0.7700\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.7537 - acc: 0.9333 - val_loss: 0.9187 - val_acc: 0.7740\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.7166 - acc: 0.9333 - val_loss: 0.9132 - val_acc: 0.7740\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.7204 - acc: 0.9500 - val_loss: 0.9077 - val_acc: 0.7780\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.7236 - acc: 0.9333 - val_loss: 0.9024 - val_acc: 0.7800\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.7040 - acc: 0.9333 - val_loss: 0.8972 - val_acc: 0.7800\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.6963 - acc: 0.9333 - val_loss: 0.8923 - val_acc: 0.7820\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.6525 - acc: 0.9667 - val_loss: 0.8875 - val_acc: 0.7820\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.6974 - acc: 0.9500 - val_loss: 0.8830 - val_acc: 0.7820\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.6710 - acc: 0.9500 - val_loss: 0.8785 - val_acc: 0.7820\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.6577 - acc: 0.9500 - val_loss: 0.8743 - val_acc: 0.7820\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.6423 - acc: 0.9500 - val_loss: 0.8703 - val_acc: 0.7840\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.6351 - acc: 0.9667 - val_loss: 0.8664 - val_acc: 0.7860\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6289 - acc: 0.9167 - val_loss: 0.8624 - val_acc: 0.7840\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.6274 - acc: 0.9500 - val_loss: 0.8585 - val_acc: 0.7840\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.5758 - acc: 0.9667 - val_loss: 0.8547 - val_acc: 0.7820\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.6528 - acc: 0.9167 - val_loss: 0.8509 - val_acc: 0.7780\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5978 - acc: 0.9833 - val_loss: 0.8472 - val_acc: 0.7800\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.6239 - acc: 0.9500 - val_loss: 0.8437 - val_acc: 0.7820\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.6039 - acc: 0.9500 - val_loss: 0.8405 - val_acc: 0.7860\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.5495 - acc: 0.9833 - val_loss: 0.8373 - val_acc: 0.7860\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.6032 - acc: 0.8833 - val_loss: 0.8342 - val_acc: 0.7860\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.5529 - acc: 0.9833 - val_loss: 0.8311 - val_acc: 0.7880\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.5679 - acc: 0.9500 - val_loss: 0.8279 - val_acc: 0.7880\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 0.5785 - acc: 0.9833 - val_loss: 0.8247 - val_acc: 0.7880\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 0.5582 - acc: 0.9500 - val_loss: 0.8219 - val_acc: 0.7900\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.5209 - acc: 0.9500 - val_loss: 0.8192 - val_acc: 0.7920\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 0.5534 - acc: 0.9667 - val_loss: 0.8167 - val_acc: 0.7920\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 265ms/step - loss: 0.5207 - acc: 0.9500 - val_loss: 0.8144 - val_acc: 0.7940\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.4844 - acc: 0.9667 - val_loss: 0.8123 - val_acc: 0.7900\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 271ms/step - loss: 0.5310 - acc: 0.9333 - val_loss: 0.8103 - val_acc: 0.7900\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.5114 - acc: 0.9667 - val_loss: 0.8082 - val_acc: 0.7880\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5285 - acc: 0.9500 - val_loss: 0.8061 - val_acc: 0.7880\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.5308 - acc: 0.9667 - val_loss: 0.8043 - val_acc: 0.7880\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4967 - acc: 0.9833 - val_loss: 0.8026 - val_acc: 0.7880\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.4849 - acc: 0.9500 - val_loss: 0.8009 - val_acc: 0.7880\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.5356 - acc: 0.9500 - val_loss: 0.7988 - val_acc: 0.7940\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.4878 - acc: 0.9500 - val_loss: 0.7970 - val_acc: 0.7940\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.5045 - acc: 0.9833 - val_loss: 0.7954 - val_acc: 0.7920\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4769 - acc: 0.9667 - val_loss: 0.7937 - val_acc: 0.7920\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.5176 - acc: 0.9500 - val_loss: 0.7920 - val_acc: 0.7880\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.4901 - acc: 0.9667 - val_loss: 0.7900 - val_acc: 0.7880\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.4713 - acc: 0.9667 - val_loss: 0.7879 - val_acc: 0.7920\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.4857 - acc: 0.9667 - val_loss: 0.7857 - val_acc: 0.7920\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.4445 - acc: 0.9833 - val_loss: 0.7836 - val_acc: 0.7960\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.4626 - acc: 0.9833 - val_loss: 0.7814 - val_acc: 0.8000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.4322 - acc: 0.9667 - val_loss: 0.7794 - val_acc: 0.8020\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4631 - acc: 0.9667 - val_loss: 0.7778 - val_acc: 0.8020\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4459 - acc: 0.9833 - val_loss: 0.7762 - val_acc: 0.8020\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4593 - acc: 0.9667 - val_loss: 0.7748 - val_acc: 0.8020\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.4498 - acc: 0.9667 - val_loss: 0.7738 - val_acc: 0.7980\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.4654 - acc: 0.9667 - val_loss: 0.7727 - val_acc: 0.8000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.4339 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.8000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.4594 - acc: 0.9500 - val_loss: 0.7703 - val_acc: 0.7980\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.4250 - acc: 0.9667 - val_loss: 0.7696 - val_acc: 0.7960\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.4362 - acc: 0.9833 - val_loss: 0.7689 - val_acc: 0.7940\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.4316 - acc: 0.9667 - val_loss: 0.7682 - val_acc: 0.7940\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.4327 - acc: 1.0000 - val_loss: 0.7676 - val_acc: 0.7920\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.4465 - acc: 0.9833 - val_loss: 0.7668 - val_acc: 0.7940\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.4470 - acc: 0.9500 - val_loss: 0.7660 - val_acc: 0.7940\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.4236 - acc: 0.9667 - val_loss: 0.7652 - val_acc: 0.7940\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4035 - acc: 0.9667 - val_loss: 0.7640 - val_acc: 0.7920\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.4466 - acc: 0.9833 - val_loss: 0.7628 - val_acc: 0.7920\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.4406 - acc: 0.9333 - val_loss: 0.7616 - val_acc: 0.7900\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.4160 - acc: 0.9500 - val_loss: 0.7606 - val_acc: 0.7900\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.4023 - acc: 0.9833 - val_loss: 0.7595 - val_acc: 0.7880\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.4012 - acc: 0.9667 - val_loss: 0.7584 - val_acc: 0.7880\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.4056 - acc: 0.9833 - val_loss: 0.7569 - val_acc: 0.7880\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.3689 - acc: 0.9833 - val_loss: 0.7556 - val_acc: 0.7900\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.3577 - acc: 0.9833 - val_loss: 0.7542 - val_acc: 0.7900\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3997 - acc: 0.9667 - val_loss: 0.7531 - val_acc: 0.7900\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 0.4120 - acc: 0.9833 - val_loss: 0.7516 - val_acc: 0.7920\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.4035 - acc: 0.9833 - val_loss: 0.7504 - val_acc: 0.7940\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.3781 - acc: 0.9833 - val_loss: 0.7490 - val_acc: 0.7960\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3923 - acc: 0.9667 - val_loss: 0.7478 - val_acc: 0.7980\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.4180 - acc: 0.9833 - val_loss: 0.7468 - val_acc: 0.7880\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3946 - acc: 0.9833 - val_loss: 0.7461 - val_acc: 0.7880\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3930 - acc: 0.9833 - val_loss: 0.7452 - val_acc: 0.7880\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.4122 - acc: 0.9833 - val_loss: 0.7441 - val_acc: 0.7880\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.3559 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 0.7880\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3590 - acc: 0.9833 - val_loss: 0.7412 - val_acc: 0.7880\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.3966 - acc: 0.9833 - val_loss: 0.7402 - val_acc: 0.7880\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.3546 - acc: 0.9833 - val_loss: 0.7398 - val_acc: 0.7880\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3946 - acc: 0.9333 - val_loss: 0.7392 - val_acc: 0.7880\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3570 - acc: 1.0000 - val_loss: 0.7386 - val_acc: 0.7900\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.3759 - acc: 0.9667 - val_loss: 0.7383 - val_acc: 0.7880\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.3802 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.7880\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3486 - acc: 0.9833 - val_loss: 0.7373 - val_acc: 0.7880\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.3569 - acc: 0.9833 - val_loss: 0.7368 - val_acc: 0.7900\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.3500 - acc: 0.9833 - val_loss: 0.7362 - val_acc: 0.7900\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.3541 - acc: 0.9667 - val_loss: 0.7357 - val_acc: 0.7900\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 277ms/step - loss: 0.3572 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.7880\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.3672 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.7840\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.3592 - acc: 0.9833 - val_loss: 0.7331 - val_acc: 0.7880\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.3936 - acc: 0.9833 - val_loss: 0.7324 - val_acc: 0.7880\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 312ms/step - loss: 0.3192 - acc: 0.9833 - val_loss: 0.7322 - val_acc: 0.7880\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.3447 - acc: 0.9667 - val_loss: 0.7316 - val_acc: 0.7840\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.3339 - acc: 0.9833 - val_loss: 0.7310 - val_acc: 0.7840\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.3766 - acc: 0.9667 - val_loss: 0.7303 - val_acc: 0.7840\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3267 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.7880\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.3470 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.7840\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3068 - acc: 0.9833 - val_loss: 0.7273 - val_acc: 0.7840\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3521 - acc: 0.9667 - val_loss: 0.7266 - val_acc: 0.7880\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3283 - acc: 0.9833 - val_loss: 0.7262 - val_acc: 0.7860\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3714 - acc: 0.9833 - val_loss: 0.7257 - val_acc: 0.7860\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3504 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 0.7840\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3309 - acc: 0.9833 - val_loss: 0.7245 - val_acc: 0.7860\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3376 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.7840\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3466 - acc: 0.9833 - val_loss: 0.7240 - val_acc: 0.7820\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.3462 - acc: 0.9833 - val_loss: 0.7236 - val_acc: 0.7780\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3726 - acc: 1.0000 - val_loss: 0.7233 - val_acc: 0.7800\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.3226 - acc: 1.0000 - val_loss: 0.7222 - val_acc: 0.7800\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3498 - acc: 1.0000 - val_loss: 0.7211 - val_acc: 0.7820\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.3307 - acc: 1.0000 - val_loss: 0.7198 - val_acc: 0.7840\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.3449 - acc: 0.9667 - val_loss: 0.7186 - val_acc: 0.7840\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3333 - acc: 0.9500 - val_loss: 0.7181 - val_acc: 0.7840\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3074 - acc: 1.0000 - val_loss: 0.7178 - val_acc: 0.7840\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.3313 - acc: 1.0000 - val_loss: 0.7168 - val_acc: 0.7860\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3215 - acc: 1.0000 - val_loss: 0.7158 - val_acc: 0.7860\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3550 - acc: 1.0000 - val_loss: 0.7146 - val_acc: 0.7840\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3217 - acc: 0.9833 - val_loss: 0.7136 - val_acc: 0.7840\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2985 - acc: 0.9833 - val_loss: 0.7128 - val_acc: 0.7860\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3631 - acc: 0.9833 - val_loss: 0.7123 - val_acc: 0.7860\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.3478 - acc: 0.9833 - val_loss: 0.7120 - val_acc: 0.7860\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.3530 - acc: 0.9500 - val_loss: 0.7124 - val_acc: 0.7860\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2950 - acc: 1.0000 - val_loss: 0.7126 - val_acc: 0.7860\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.3187 - acc: 1.0000 - val_loss: 0.7125 - val_acc: 0.7860\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3137 - acc: 0.9833 - val_loss: 0.7123 - val_acc: 0.7860\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3293 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.7860\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.3215 - acc: 0.9833 - val_loss: 0.7113 - val_acc: 0.7880\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.3004 - acc: 0.9833 - val_loss: 0.7106 - val_acc: 0.7900\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.3271 - acc: 0.9833 - val_loss: 0.7093 - val_acc: 0.7900\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.3138 - acc: 0.9833 - val_loss: 0.7081 - val_acc: 0.7920\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3073 - acc: 0.9833 - val_loss: 0.7072 - val_acc: 0.7900\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3246 - acc: 0.9833 - val_loss: 0.7064 - val_acc: 0.7900\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3253 - acc: 0.9667 - val_loss: 0.7061 - val_acc: 0.7900\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.3108 - acc: 1.0000 - val_loss: 0.7054 - val_acc: 0.7900\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.3085 - acc: 1.0000 - val_loss: 0.7049 - val_acc: 0.7840\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.2962 - acc: 0.9833 - val_loss: 0.7049 - val_acc: 0.7840\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3364 - acc: 0.9667 - val_loss: 0.7054 - val_acc: 0.7900\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.2884 - acc: 1.0000 - val_loss: 0.7060 - val_acc: 0.7900\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.3216 - acc: 1.0000 - val_loss: 0.7072 - val_acc: 0.7900\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.2971 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.7880\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.3240 - acc: 0.9667 - val_loss: 0.7088 - val_acc: 0.7900\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.3112 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.7900\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.2975 - acc: 1.0000 - val_loss: 0.7093 - val_acc: 0.7900\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 311ms/step - loss: 0.3015 - acc: 0.9833 - val_loss: 0.7086 - val_acc: 0.7900\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.3312 - acc: 1.0000 - val_loss: 0.7077 - val_acc: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2cb0a4c250>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "55UF7Kt04Pwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=weights_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0704e2-dc60-46ed-c9ac-b6ff123840ac",
        "id": "zr7NmGdU4Pwj"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7147 - acc: 0.7910\n",
            "Done.\n",
            "Test loss: 0.7146878838539124\n",
            "Test accuracy: 0.7909999489784241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SimpleGCN Model"
      ],
      "metadata": {
        "id": "pPymTb6zN6Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 2  # Propagation steps for SGCN\n",
        "dataset = Citation(\"pubmed\", transforms=[LayerPreprocess(GCNConv), SGCN(K)])\n",
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dataset.mask_te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b802480-a051-4068-fdf3-fb70a22e0bbc",
        "id": "xdKYnimUN6Y2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train model"
      ],
      "metadata": {
        "id": "RNlvLtplN6Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_SGCN_text_classification(dataset, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587b24dc-4734-4928-c495-0a102a1e5b3f",
        "id": "GNwUCdf3N6Y2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None, 500)]                0         []                            \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)       [(None, 19717)]              0         []                            \n",
            "                                                                                                  \n",
            " gcn_conv_20 (GCNConv)       (None, 3)                    1500      ['input_9[0][0]',             \n",
            "                                                                     'input_10[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1500 (5.86 KB)\n",
            "Trainable params: 1500 (5.86 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)\n",
        "model.fit(\n",
        "    loader_tr.load(),\n",
        "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
        "    validation_data=loader_va.load(),\n",
        "    validation_steps=loader_va.steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e5b89b-d785-436e-d2c6-11ed1351fb0f",
        "id": "p-itxznJN6Y2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 628ms/step - loss: 0.0034 - acc: 0.3167 - val_loss: 0.0279 - val_acc: 0.3520\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0034 - acc: 0.4500 - val_loss: 0.0278 - val_acc: 0.4520\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - acc: 0.5667 - val_loss: 0.0277 - val_acc: 0.5160\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0033 - acc: 0.6667 - val_loss: 0.0277 - val_acc: 0.6040\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0033 - acc: 0.7500 - val_loss: 0.0276 - val_acc: 0.6300\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0033 - acc: 0.7500 - val_loss: 0.0275 - val_acc: 0.6560\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0033 - acc: 0.8167 - val_loss: 0.0275 - val_acc: 0.6760\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0033 - acc: 0.8667 - val_loss: 0.0274 - val_acc: 0.6760\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - acc: 0.8833 - val_loss: 0.0273 - val_acc: 0.6820\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0032 - acc: 0.8833 - val_loss: 0.0273 - val_acc: 0.6920\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - acc: 0.8833 - val_loss: 0.0272 - val_acc: 0.6940\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0032 - acc: 0.8833 - val_loss: 0.0271 - val_acc: 0.7000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0032 - acc: 0.8833 - val_loss: 0.0270 - val_acc: 0.7020\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0032 - acc: 0.9000 - val_loss: 0.0270 - val_acc: 0.7040\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0032 - acc: 0.9000 - val_loss: 0.0269 - val_acc: 0.7040\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0032 - acc: 0.9000 - val_loss: 0.0269 - val_acc: 0.7100\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0031 - acc: 0.9000 - val_loss: 0.0268 - val_acc: 0.7100\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0031 - acc: 0.9000 - val_loss: 0.0267 - val_acc: 0.7100\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - acc: 0.9000 - val_loss: 0.0267 - val_acc: 0.7120\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0266 - val_acc: 0.7120\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0265 - val_acc: 0.7120\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0265 - val_acc: 0.7120\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0264 - val_acc: 0.7140\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0264 - val_acc: 0.7140\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0263 - val_acc: 0.7160\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0263 - val_acc: 0.7200\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0262 - val_acc: 0.7220\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0031 - acc: 0.9167 - val_loss: 0.0262 - val_acc: 0.7220\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0261 - val_acc: 0.7240\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0261 - val_acc: 0.7300\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0261 - val_acc: 0.7300\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0260 - val_acc: 0.7300\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0260 - val_acc: 0.7320\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0259 - val_acc: 0.7300\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0259 - val_acc: 0.7300\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0259 - val_acc: 0.7300\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0258 - val_acc: 0.7300\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0258 - val_acc: 0.7300\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0258 - val_acc: 0.7300\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0258 - val_acc: 0.7320\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0257 - val_acc: 0.7320\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0257 - val_acc: 0.7320\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0257 - val_acc: 0.7320\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0257 - val_acc: 0.7300\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0256 - val_acc: 0.7300\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0256 - val_acc: 0.7320\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0256 - val_acc: 0.7320\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0256 - val_acc: 0.7320\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0256 - val_acc: 0.7320\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7320\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7320\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7320\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7320\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7340\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7360\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0255 - val_acc: 0.7340\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7340\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7360\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7360\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7360\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9333 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0254 - val_acc: 0.7380\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7380\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7380\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0030 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7420\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7440\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7440\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7440\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0253 - val_acc: 0.7440\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7440\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7460\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7460\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0252 - val_acc: 0.7460\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7460\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7500\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0251 - val_acc: 0.7480\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7480\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7460\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7460\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7460\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - acc: 0.9167 - val_loss: 0.0250 - val_acc: 0.7460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2cb0cf7820>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Evaluate"
      ],
      "metadata": {
        "id": "78QZrYfwN6Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model.\")\n",
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
        "print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5aefd5e-e97d-40c8-c531-0a4039b7d5d8",
        "id": "pk78HAnQN6Y3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model.\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0499 - acc: 0.7440\n",
            "Done.\n",
            "Test loss: 0.04988781362771988\n",
            "Test accuracy: 0.7440000176429749\n"
          ]
        }
      ]
    }
  ]
}